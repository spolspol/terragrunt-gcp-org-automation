name: Upload VM Scripts

on:
  push:
    branches:
      - main
    paths:
      - 'live/**/compute/*/scripts/*.sh'
  workflow_dispatch:
    inputs:
      force_upload:
        description: 'Force upload all scripts regardless of changes'
        required: false
        type: boolean
        default: false

concurrency:
  group: upload-vm-scripts
  cancel-in-progress: false

jobs:
  check-script-changes:
    name: 🔍 Check Script Changes
    runs-on: ubuntu-latest
    outputs:
      should-upload: ${{ steps.check.outputs.should-upload }}
    steps:
      - name: Checkout code
        uses: actions/checkout@v4
        with:
          fetch-depth: 0

      - name: Determine if upload needed
        id: check
        run: |
          if [[ "${{ github.event_name }}" == "workflow_dispatch" && "${{ inputs.force_upload }}" == "true" ]]; then
            echo "should-upload=true" >> $GITHUB_OUTPUT
            echo "✅ Force upload requested - uploading all scripts"
          elif [[ "${{ github.event_name }}" == "push" ]]; then
            echo "should-upload=true" >> $GITHUB_OUTPUT
            echo "✅ Script changes detected in push - proceeding with upload"
          elif [[ "${{ github.event_name }}" == "workflow_dispatch" ]]; then
            # For manual dispatch without force, check recent changes
            CHANGED_FILES=$(git diff --name-only HEAD~1 HEAD | grep -E '^live/.*/compute/.*/scripts/.*\.sh$' || true)
            if [[ -n "$CHANGED_FILES" ]]; then
              echo "should-upload=true" >> $GITHUB_OUTPUT
              echo "📝 Recent script changes detected:"
              echo "$CHANGED_FILES"
            else
              echo "should-upload=false" >> $GITHUB_OUTPUT
              echo "ℹ️ No recent script changes detected - use force_upload to upload anyway"
            fi
          else
            echo "should-upload=false" >> $GITHUB_OUTPUT
            echo "❌ Unknown trigger - skipping upload"
          fi

  get-env:
    name: 📋 Get ENV
    uses: ./.github/workflows/common-env.yml
    needs: [check-script-changes]
    if: needs.check-script-changes.outputs.should-upload == 'true'

  upload-scripts:
    name: 📤 Upload VM Scripts
    runs-on: ubuntu-latest
    needs: [check-script-changes, get-env]
    if: needs.check-script-changes.outputs.should-upload == 'true'
    steps:
      - name: Checkout code
        uses: actions/checkout@v4
        with:
          fetch-depth: 0  # Full history for change detection

      - name: Authenticate to Google Cloud
        uses: google-github-actions/auth@v2
        with:
          credentials_json: ${{ secrets.TF_GOOGLE_CREDENTIALS }}

      - name: Set up Cloud SDK
        uses: google-github-actions/setup-gcloud@v2

      - name: Find and upload VM scripts
        run: |
          echo "🔍 Searching for VM script directories..."

          # Find all script directories under compute instances
          script_dirs=$(find live -type d -name "scripts" -path "*/compute/*" | sort)

          if [[ -z "$script_dirs" ]]; then
            echo "❌ No script directories found"
            exit 0
          fi

          echo "📁 Found script directories:"
          echo "$script_dirs"
          echo ""

          # Process each script directory
          for script_dir in $script_dirs; do
            echo "📂 Processing: $script_dir"

            # Extract VM type and project info from path
            # Path format: live/account/env/project/region/compute/vm-type/scripts
            vm_path=$(dirname "$script_dir")
            vm_type=$(basename "$vm_path")

            # Extract project path components
            path_parts=($(echo "$script_dir" | tr '/' '\n'))
            account="${path_parts[1]}"
            env="${path_parts[2]}"
            project="${path_parts[3]}"
            region="${path_parts[4]}"

            echo "  VM Type: $vm_type"
            echo "  Account: $account"
            echo "  Environment: $env"
            echo "  Project: $project"
            echo "  Region: $region"

            # Determine project ID based on project path
            case "$project" in
              "web-project")
                # For web-project, we need to discover the actual project ID
                # This is a known project in the example environment
                PROJECT_ID=$(gcloud projects list --filter="name:*web-project*" --format="value(projectId)" --limit=1 2>/dev/null || echo "")
                if [[ -z "$PROJECT_ID" ]]; then
                  echo "❌ Could not find web-project project ID - skipping"
                  continue
                fi
                ;;
              *)
                # For other projects, try to use the project name as the ID
                PROJECT_ID="$project"
                ;;
            esac

            echo "  Project ID: $PROJECT_ID"

            # Set GCP project context
            gcloud config set project "$PROJECT_ID"

            # Discover bucket using pattern matching
            echo "  🔍 Discovering vm-scripts bucket..."
            BUCKET_NAME=$(gsutil ls -p "$PROJECT_ID" | grep "gs://.*vm-scripts" | head -1 | sed 's|gs://||' | sed 's|/$||')

            if [[ -z "$BUCKET_NAME" ]]; then
              echo "❌ No vm-scripts bucket found in project $PROJECT_ID - skipping"
              continue
            fi

            echo "  Target bucket: gs://$BUCKET_NAME"
            echo "  Target path: $vm_type/"

            # Check if bucket exists
            if ! gsutil ls "gs://$BUCKET_NAME" >/dev/null 2>&1; then
              echo "❌ Bucket gs://$BUCKET_NAME does not exist - skipping"
              continue
            fi

            # Check if scripts directory has files
            script_files=$(find "$script_dir" -type f -name "*.sh" | wc -l)
            if [[ $script_files -eq 0 ]]; then
              echo "⚠️  No .sh files found in $script_dir - skipping"
              continue
            fi

            echo "  Found $script_files shell script(s)"

            # Upload scripts to appropriate folder in bucket
            echo "  📤 Uploading scripts..."

            # Create target directory structure in bucket
            gsutil -m cp -r "$script_dir"/*.sh "gs://$BUCKET_NAME/$vm_type/" || {
              echo "❌ Failed to upload scripts from $script_dir"
              exit 1
            }

            echo "  ✅ Successfully uploaded scripts from $script_dir"
            echo ""
          done

          echo "🎉 All VM scripts uploaded successfully!"

      - name: Verify uploads
        run: |
          echo "🔍 Verifying uploaded scripts..."

          # List all uploaded scripts for verification
          for script_dir in $(find live -type d -name "scripts" -path "*/compute/*" | sort); do
            vm_path=$(dirname "$script_dir")
            vm_type=$(basename "$vm_path")

            # Extract project info
            path_parts=($(echo "$script_dir" | tr '/' '\n'))
            project="${path_parts[3]}"

            case "$project" in
              "web-project")
                # Discover project ID
                PROJECT_ID=$(gcloud projects list --filter="name:*web-project*" --format="value(projectId)" --limit=1 2>/dev/null || echo "")
                if [[ -z "$PROJECT_ID" ]]; then
                  continue
                fi
                # Set project context and discover bucket
                gcloud config set project "$PROJECT_ID"
                BUCKET_NAME=$(gsutil ls -p "$PROJECT_ID" | grep "gs://.*vm-scripts" | head -1 | sed 's|gs://||' | sed 's|/$||')
                if [[ -z "$BUCKET_NAME" ]]; then
                  continue
                fi
                ;;
              *)
                continue
                ;;
            esac

            echo "📋 Scripts in gs://$BUCKET_NAME/$vm_type/:"
            gsutil ls "gs://$BUCKET_NAME/$vm_type/" || echo "  (empty or not found)"
            echo ""
          done

  workflow-summary:
    name: 📊 Workflow Summary
    runs-on: ubuntu-latest
    needs: [check-script-changes, upload-scripts]
    if: always()
    steps:
      - name: Generate workflow summary
        run: |
          echo "## 📤 VM Scripts Upload Summary" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY

          # Check why workflow ran
          if [[ "${{ github.event_name }}" == "workflow_dispatch" ]]; then
            echo "**Trigger**: Manual workflow dispatch" >> $GITHUB_STEP_SUMMARY
            if [[ "${{ inputs.force_upload }}" == "true" ]]; then
              echo "**Mode**: Force upload (all scripts)" >> $GITHUB_STEP_SUMMARY
            else
              echo "**Mode**: Normal upload (changed scripts only)" >> $GITHUB_STEP_SUMMARY
            fi
          elif [[ "${{ github.event_name }}" == "push" ]]; then
            echo "**Trigger**: Automatic (script changes detected)" >> $GITHUB_STEP_SUMMARY
            echo "**Branch**: ${{ github.ref_name }}" >> $GITHUB_STEP_SUMMARY
          fi

          echo "" >> $GITHUB_STEP_SUMMARY

          # Check execution results
          if [[ "${{ needs.check-script-changes.outputs.should-upload }}" != "true" ]]; then
            echo "ℹ️ **Result**: Upload skipped" >> $GITHUB_STEP_SUMMARY
            echo "**Reason**: No script changes detected" >> $GITHUB_STEP_SUMMARY
          elif [[ "${{ needs.upload-scripts.result }}" == "success" ]]; then
            echo "✅ **Result**: Scripts uploaded successfully" >> $GITHUB_STEP_SUMMARY
            echo "**Scripts**: Updated in GCS vm-scripts buckets" >> $GITHUB_STEP_SUMMARY
          elif [[ "${{ needs.upload-scripts.result }}" == "failure" ]]; then
            echo "❌ **Result**: Upload failed" >> $GITHUB_STEP_SUMMARY
            echo "**Reason**: Check upload job logs for details" >> $GITHUB_STEP_SUMMARY
          else
            echo "⚠️ **Result**: Upload skipped" >> $GITHUB_STEP_SUMMARY
            echo "**Reason**: Conditions not met" >> $GITHUB_STEP_SUMMARY
          fi

          echo "" >> $GITHUB_STEP_SUMMARY
          echo "**Next Steps**:" >> $GITHUB_STEP_SUMMARY
          if [[ "${{ needs.upload-scripts.result }}" == "success" ]]; then
            echo "- Scripts are now available for VM instance deployments" >> $GITHUB_STEP_SUMMARY
            echo "- New instances will automatically download latest scripts" >> $GITHUB_STEP_SUMMARY
          else
            echo "- Scripts were not updated in GCS" >> $GITHUB_STEP_SUMMARY
            echo "- VM instances will continue using previously uploaded scripts" >> $GITHUB_STEP_SUMMARY
          fi
